{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Notes:</b>\n",
    "<br> - Each cell has its own notes.\n",
    "<br> - I tried Multi linear regression, Polynomial regression, and random forest regression.\n",
    "<br> - For some reason, the result we got locally is better than the one we get on Kaggle!\n",
    "<br> - Some output couldn't reduce the volume (like data.info()).\n",
    "<br> - I tried several encoding techniques, (one-hot encoding was painful, \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt_path = \"../data/train.csv\"\n",
    "test_dt_path = \"../data/test.csv\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(train_dt_path)\n",
    "Kaggle_testing_data = pd.read_csv(test_dt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle_testing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Step: Feature processing ( remove Empty features, populate Nan Values,Encode, Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I removed the features that have more than 50% values of NaN.  \n",
    "- I removed Id, Utilities & FireplaceQu, because they have only one value for all the feature and because Id is not needed in the prediction process.  \n",
    "- I am preparing the train set and the test set together so I could use test_set on Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y = data['SalePrice']\n",
    "X = data.drop(['SalePrice'], axis =1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "X_final_train, X_val, y_final_train, y_val = train_test_split(X_train, y_train, test_size = 0.4, random_state = 0)\n",
    "\n",
    "perc = 50.0\n",
    "min_count_Train =  int(((100-perc)/100)*X_final_train.shape[0] + 1)\n",
    "min_count_Val =  int(((100-perc)/100)*X_val.shape[0] + 1)\n",
    "min_count_Test =  int(((100-perc)/100)*X_test.shape[0] + 1)\n",
    "min_count_Kaggle_Test =  int(((100-perc)/100)*Kaggle_testing_data.shape[0] + 1)\n",
    "\n",
    "\n",
    "X_final_train.dropna( axis=1,\n",
    "                thresh=min_count_Train, inplace=True)\n",
    "X_val.dropna( axis=1,\n",
    "                thresh=min_count_Val, inplace=True)\n",
    "X_test.dropna( axis=1,\n",
    "                thresh=min_count_Test, inplace=True)\n",
    "Kaggle_testing_data.dropna(axis=1,\n",
    "                thresh=min_count_Kaggle_Test, inplace=True)\n",
    "\n",
    "\n",
    "X_final_train = X_final_train.drop(['Id','Utilities','FireplaceQu'], axis=1)\n",
    "X_val = X_val.drop(['Id','Utilities'], axis=1)\n",
    "X_test = X_test.drop(['Id','Utilities','FireplaceQu'], axis=1)\n",
    "# ids = pd.DataFrame()\n",
    "# ids['Id'] = Kaggle_testing_data['Id']\n",
    "Kaggle_testing_data = Kaggle_testing_data.drop(['Id','Utilities'], axis=1)\n",
    "# print(X_val.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_final_train['MSSubClass'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Features to: Numeric, Ordinal, and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_Train = X_final_train.select_dtypes('object')\n",
    "\n",
    "categorical_features_Train_Ordinal = categorical_features_Train[['MSZoning', 'LandSlope','BldgType','RoofMatl','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC'\n",
    ",'CentralAir','Electrical','KitchenQual','Functional','GarageFinish','GarageQual','GarageCond','PavedDrive','SaleCondition']]\n",
    "\n",
    "categorical_features_Train_Not_Ordinal = categorical_features_Train[['Street','LotShape','LandContour','LotConfig','Neighborhood','Condition1','Condition2','HouseStyle','RoofStyle','Exterior1st','Exterior2nd'\n",
    ",'MasVnrType','Foundation','Heating','GarageType','SaleType']]\n",
    "\n",
    "\n",
    "categorical_features_Val = X_val.select_dtypes('object')\n",
    "\n",
    "categorical_features_Val_Ordinal = categorical_features_Val[['MSZoning', 'LandSlope','BldgType','RoofMatl','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC'\n",
    ",'CentralAir','Electrical','KitchenQual','Functional','GarageFinish','GarageQual','GarageCond','PavedDrive','SaleCondition']]\n",
    "\n",
    "categorical_features_Val_Not_Ordinal = categorical_features_Val[['Street','LotShape','LandContour','LotConfig','Neighborhood','Condition1','Condition2','HouseStyle','RoofStyle','Exterior1st','Exterior2nd'\n",
    ",'MasVnrType','Foundation','Heating','GarageType','SaleType']]\n",
    "\n",
    "\n",
    "\n",
    "categorical_features_Test = X_test.select_dtypes('object')\n",
    "\n",
    "categorical_features_Test_Ordinal = categorical_features_Test[['MSZoning', 'LandSlope','BldgType','RoofMatl','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC'\n",
    ",'CentralAir','Electrical','KitchenQual','Functional','GarageFinish','GarageQual','GarageCond','PavedDrive','SaleCondition']]\n",
    "\n",
    "categorical_features_Test_Not_Ordinal = categorical_features_Test[['Street','LotShape','LandContour','LotConfig','Neighborhood','Condition1','Condition2','HouseStyle','RoofStyle','Exterior1st','Exterior2nd'\n",
    ",'MasVnrType','Foundation','Heating','GarageType','SaleType']]\n",
    "\n",
    "\n",
    "\n",
    "# print(categorical_features_Test_Not_Ordinal.head(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------- for Kaggle ----------------------------------------------------------------------\n",
    "categorical_features_Kaggle_Testing = Kaggle_testing_data.select_dtypes('object')\n",
    "\n",
    "categorical_features_Kaggle_Testing_Ordinal = categorical_features_Kaggle_Testing[['MSZoning', 'LandSlope','BldgType','RoofMatl','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC'\n",
    ",'CentralAir','Electrical','KitchenQual','Functional','GarageFinish','GarageQual','GarageCond','PavedDrive','SaleCondition']]\n",
    "\n",
    "categorical_features_Kaggle_Testing_Not_Ordinal = categorical_features_Kaggle_Testing[['Street','LotShape','LandContour','LotConfig','Neighborhood','Condition1','Condition2','HouseStyle','RoofStyle','Exterior1st','Exterior2nd'\n",
    ",'MasVnrType','Foundation','Heating','GarageType','SaleType']]\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features_Train_Ordinal['MSZoning'].unique()\n",
    "# categorical_features_Train_Not_Ordinal.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Ordinal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 468 entries, 0 to 467\n",
      "Columns: 117 entries, Street_Pave to SaleType_Oth\n",
      "dtypes: float64(117)\n",
      "memory usage: 427.9 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def get_Encoded_OneHot_Encoder(categorical_features_Not_Ord):\n",
    "    cat_cols = categorical_features_Not_Ord.columns.values\n",
    "    cols_encoded = []\n",
    "    for col in cat_cols:\n",
    "        cols_encoded += [f\"{col}_{cat}\" for cat in list(categorical_features_Not_Ord[col].unique())]\n",
    "    oh_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    encoded_cols = oh_encoder.fit_transform(categorical_features_Not_Ord[cat_cols])\n",
    "    df_enc = pd.DataFrame(encoded_cols, columns=cols_encoded)\n",
    "    return df_enc\n",
    "\n",
    "def get_Encoded_Ordinal(categorical_features_Ord):\n",
    "    cat_encoded = pd.DataFrame()\n",
    "    for i in range(len(categorical_features_Ord.columns)):\n",
    "        ColName = categorical_features_Ord.columns[i]\n",
    "        enc = OrdinalEncoder()\n",
    "        temp = enc.fit_transform(categorical_features_Ord[[ColName]])\n",
    "        finall = pd.concat([\n",
    "        cat_encoded,\n",
    "        pd.DataFrame(\n",
    "            temp,\n",
    "            columns=[ColName]\n",
    "        )\n",
    "        ],axis=1)\n",
    "        cat_encoded = finall\n",
    "    return cat_encoded\n",
    "\n",
    "Train_ordinal = get_Encoded_Ordinal(categorical_features_Train_Ordinal)\n",
    "Val_ordinal = get_Encoded_Ordinal(categorical_features_Val_Ordinal)\n",
    "Test_ordinal = get_Encoded_Ordinal(categorical_features_Test_Ordinal)\n",
    "Kaggle_Testing_ordinal = get_Encoded_Ordinal(categorical_features_Kaggle_Testing_Ordinal)\n",
    "\n",
    "Train_Not_ordinal = get_Encoded_OneHot_Encoder(categorical_features_Train_Not_Ordinal)\n",
    "Val_Not_ordinal = get_Encoded_OneHot_Encoder(categorical_features_Val_Not_Ordinal)\n",
    "Test_Not_ordinal = get_Encoded_OneHot_Encoder(categorical_features_Test_Not_Ordinal)\n",
    "Kaggle_Testing_Not_ordinal = get_Encoded_OneHot_Encoder(categorical_features_Kaggle_Testing_Not_Ordinal)\n",
    "\n",
    "Val_Not_ordinal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 468 entries, 1425 to 370\n",
      "Data columns (total 57 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     468 non-null    int64  \n",
      " 1   LotFrontage    468 non-null    float64\n",
      " 2   LotArea        468 non-null    int64  \n",
      " 3   OverallQual    468 non-null    int64  \n",
      " 4   OverallCond    468 non-null    int64  \n",
      " 5   YearBuilt      468 non-null    int64  \n",
      " 6   YearRemodAdd   468 non-null    int64  \n",
      " 7   MasVnrArea     468 non-null    float64\n",
      " 8   BsmtFinSF1     468 non-null    int64  \n",
      " 9   BsmtFinSF2     468 non-null    int64  \n",
      " 10  BsmtUnfSF      468 non-null    int64  \n",
      " 11  TotalBsmtSF    468 non-null    int64  \n",
      " 12  1stFlrSF       468 non-null    int64  \n",
      " 13  2ndFlrSF       468 non-null    int64  \n",
      " 14  LowQualFinSF   468 non-null    int64  \n",
      " 15  GrLivArea      468 non-null    int64  \n",
      " 16  BsmtFullBath   468 non-null    int64  \n",
      " 17  BsmtHalfBath   468 non-null    int64  \n",
      " 18  FullBath       468 non-null    int64  \n",
      " 19  HalfBath       468 non-null    int64  \n",
      " 20  BedroomAbvGr   468 non-null    int64  \n",
      " 21  KitchenAbvGr   468 non-null    int64  \n",
      " 22  TotRmsAbvGrd   468 non-null    int64  \n",
      " 23  Fireplaces     468 non-null    int64  \n",
      " 24  GarageYrBlt    468 non-null    float64\n",
      " 25  GarageCars     468 non-null    int64  \n",
      " 26  GarageArea     468 non-null    int64  \n",
      " 27  WoodDeckSF     468 non-null    int64  \n",
      " 28  OpenPorchSF    468 non-null    int64  \n",
      " 29  EnclosedPorch  468 non-null    int64  \n",
      " 30  3SsnPorch      468 non-null    int64  \n",
      " 31  ScreenPorch    468 non-null    int64  \n",
      " 32  PoolArea       468 non-null    int64  \n",
      " 33  MiscVal        468 non-null    int64  \n",
      " 34  MoSold         468 non-null    int64  \n",
      " 35  YrSold         468 non-null    int64  \n",
      " 36  MSZoning       468 non-null    float64\n",
      " 37  LandSlope      468 non-null    float64\n",
      " 38  BldgType       468 non-null    float64\n",
      " 39  RoofMatl       468 non-null    float64\n",
      " 40  ExterQual      468 non-null    float64\n",
      " 41  ExterCond      468 non-null    float64\n",
      " 42  BsmtQual       468 non-null    float64\n",
      " 43  BsmtCond       468 non-null    float64\n",
      " 44  BsmtExposure   468 non-null    float64\n",
      " 45  BsmtFinType1   468 non-null    float64\n",
      " 46  BsmtFinType2   468 non-null    float64\n",
      " 47  HeatingQC      468 non-null    float64\n",
      " 48  CentralAir     468 non-null    float64\n",
      " 49  Electrical     468 non-null    float64\n",
      " 50  KitchenQual    468 non-null    float64\n",
      " 51  Functional     468 non-null    float64\n",
      " 52  GarageFinish   468 non-null    float64\n",
      " 53  GarageQual     468 non-null    float64\n",
      " 54  GarageCond     468 non-null    float64\n",
      " 55  PavedDrive     468 non-null    float64\n",
      " 56  SaleCondition  468 non-null    float64\n",
      "dtypes: float64(24), int64(33)\n",
      "memory usage: 228.2 KB\n"
     ]
    }
   ],
   "source": [
    "numeric_features_Train = X_final_train.select_dtypes('number')\n",
    "numeric_features_Val = X_val.select_dtypes('number')\n",
    "numeric_features_Test = X_test.select_dtypes('number')\n",
    "numeric_features_Kaggle_Testing = Kaggle_testing_data.select_dtypes('number')\n",
    "\n",
    "f_Train = numeric_features_Train.join(Train_ordinal)\n",
    "f_Val = numeric_features_Val.join(Val_ordinal)\n",
    "f_Test = numeric_features_Test.join(Test_ordinal)\n",
    "f_Kaggle_Testing = numeric_features_Kaggle_Testing.join(Kaggle_Testing_ordinal)\n",
    "        \n",
    "f_Train = f_Train.fillna(f_Train.median())\n",
    "f_Val = f_Val.fillna(f_Val.median())\n",
    "f_Test = f_Test.fillna(f_Test.median())\n",
    "f_Kaggle_Testing = f_Kaggle_Testing.fillna(f_Kaggle_Testing.median())\n",
    "\n",
    "# print(f_Train.info())\n",
    "f_Val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f_Val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = f_Train.join(Y)\n",
    "\n",
    "# correlation = temp.corr()\n",
    "# # # print(correlation)\n",
    "# correlation.to_csv('../training_featuresss.csv')\n",
    "\n",
    "# temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 700 entries, 1130 to 1306\n",
      "Columns: 137 entries, OverallQual to SaleType_Oth\n",
      "dtypes: float64(128), int64(9)\n",
      "memory usage: 770.9 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 468 entries, 1425 to 370\n",
      "Columns: 128 entries, OverallQual to SaleType_Oth\n",
      "dtypes: float64(119), int64(9)\n",
      "memory usage: 487.8 KB\n"
     ]
    }
   ],
   "source": [
    "# print(Train_Not_ordinal.head(5))\n",
    "\n",
    "final_Train = f_Train[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageYrBlt','GarageCars']].join(Train_Not_ordinal)\n",
    "final_Val = f_Val[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageYrBlt','GarageCars']].join(Val_Not_ordinal)\n",
    "final_Test = f_Test[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageYrBlt','GarageCars']].join(Test_Not_ordinal)\n",
    "final_Kaggle_Testing = f_Kaggle_Testing[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','GarageYrBlt','GarageCars']].join(Kaggle_Testing_Not_ordinal)\n",
    "\n",
    "final_Train.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "final_Train.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "\n",
    "final_Val.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "final_Val.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "\n",
    "final_Test.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "final_Test.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "\n",
    "final_Kaggle_Testing.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "final_Kaggle_Testing.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "\n",
    "\n",
    "# final_Train.to_csv('../checkNOTordinal.csv')\n",
    "print(final_Train.info())\n",
    "final_Val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for i in final_Train.columns:\n",
    "    final_Train[i] = scaler.fit_transform(final_Train[[i]])\n",
    "\n",
    "for i in final_Val.columns:\n",
    "    final_Val[i] = scaler.fit_transform(final_Val[[i]])\n",
    "\n",
    "for i in final_Test.columns:\n",
    "    final_Test[i] = scaler.fit_transform(final_Test[[i]])\n",
    "\n",
    "for i in final_Kaggle_Testing.columns:\n",
    "    final_Kaggle_Testing[i] = scaler.fit_transform(final_Kaggle_Testing[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 468 entries, 1425 to 370\n",
      "Columns: 128 entries, OverallQual to SaleType_Oth\n",
      "dtypes: float64(128)\n",
      "memory usage: 487.8 KB\n"
     ]
    }
   ],
   "source": [
    "final_Val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 919 entries, 1139 to 576\n",
      "Columns: 142 entries, OverallQual to SaleType_Oth\n",
      "dtypes: float64(142)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "final_Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Exterior1st_ImStucc\n",
      "- Exterior2nd_Other\n",
      "- SaleType_Con\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Condition2_Artery\n",
      "- Condition2_PosA\n",
      "- Condition2_RRAe\n",
      "- Condition2_RRNn\n",
      "- Exterior1st_AsphShn\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 126 features, but RandomForestRegressor is expecting 142 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive - Lebanese American University\\France\\EPITA_Semesters\\S2\\DS in Production\\DSA-S22-CV-env\\notebooks\\house-prices-modeling-1.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20Lebanese%20American%20University/France/EPITA_Semesters/S2/DS%20in%20Production/DSA-S22-CV-env/notebooks/house-prices-modeling-1.ipynb#ch0000053?line=2'>3</a>\u001b[0m mod \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20Lebanese%20American%20University/France/EPITA_Semesters/S2/DS%20in%20Production/DSA-S22-CV-env/notebooks/house-prices-modeling-1.ipynb#ch0000053?line=3'>4</a>\u001b[0m mod\u001b[39m.\u001b[39mfit(final_Train,y_final_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20Lebanese%20American%20University/France/EPITA_Semesters/S2/DS%20in%20Production/DSA-S22-CV-env/notebooks/house-prices-modeling-1.ipynb#ch0000053?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39;49mpredict(final_Val)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20Lebanese%20American%20University/France/EPITA_Semesters/S2/DS%20in%20Production/DSA-S22-CV-env/notebooks/house-prices-modeling-1.ipynb#ch0000053?line=5'>6</a>\u001b[0m compute_rmsle(y_val,y_pred)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:971\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=968'>969</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=969'>970</a>\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=970'>971</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=972'>973</a>\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=973'>974</a>\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=575'>576</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=576'>577</a>\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=577'>578</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=578'>579</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=579'>580</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/ensemble/_forest.py?line=580'>581</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=584'>585</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=396'>397</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=398'>399</a>\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=399'>400</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=400'>401</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=401'>402</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/miniconda3/envs/ml/lib/site-packages/sklearn/base.py?line=402'>403</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 126 features, but RandomForestRegressor is expecting 142 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# mod = RandomForestRegressor()\n",
    "# mod.fit(final_Train,y_final_train)\n",
    "# y_pred = mod.predict(final_Val)\n",
    "# compute_rmsle(y_val,y_pred)\n",
    "\n",
    "# X_final_train, X_val, y_final_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_Train.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in this cell, I splitted the features to numeric & categorical.  \n",
    "* I filled the numeric missing data with the median of each feature.  \n",
    "* I Encoded the categorical features using OrdinalEncoder.  \n",
    "* I used Interpolator in order to fill the missing values in the categorical features.  \n",
    "* I merged the features (continuous & categorical) together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# categorical_features = X.select_dtypes('object')\n",
    "# continuous_features = X.select_dtypes('number')\n",
    "# continuous_features = continuous_features.fillna(continuous_features.median())\n",
    "\n",
    "# test_continuous_features = Kaggle_testing_data.select_dtypes('number')\n",
    "# test_categorical_features = Kaggle_testing_data.select_dtypes('object')\n",
    "# test_continuous_features = test_continuous_features.fillna(test_continuous_features.median())\n",
    "\n",
    "\n",
    "# cat_encoded = get_Encoded(categorical_features)\n",
    "# test_cat_encoded = get_Encoded(test_categorical_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cat_encoded.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "# cat_encoded.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "# f = pd.concat([\n",
    "#     continuous_features,\n",
    "#     pd.DataFrame(\n",
    "#         cat_encoded\n",
    "#     )\n",
    "#     ],axis=1)\n",
    "\n",
    "\n",
    "# test_cat_encoded.interpolate(method ='linear', limit_direction ='forward', inplace=True)\n",
    "# test_cat_encoded.interpolate(method ='linear', limit_direction ='backward', inplace=True)\n",
    "# test_f = pd.concat([\n",
    "#     test_continuous_features,\n",
    "#     pd.DataFrame(\n",
    "#         test_cat_encoded\n",
    "#     )\n",
    "#     ],axis=1)\n",
    "# f.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Step: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I concatenated SalePrice to my preprocessed_X and I computed the correlation matrix to see if there is any linear correlation between features.  \n",
    "* I printed the result on a file because it is huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = pd.concat([\n",
    "#     f,\n",
    "#     pd.DataFrame(\n",
    "#         Y,\n",
    "#         index=Y.index,\n",
    "#         columns=['SalePrice']\n",
    "#     )\n",
    "# ],axis=1)\n",
    "\n",
    "# correlation = temp.corr()\n",
    "# # print(correlation)\n",
    "# correlation.to_csv('../training_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I checked the correlation matrix file, I found out that these are the features that have 0.5 or more, -0.5 or less linear correlation wth SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_final_X = f[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF',\n",
    "# '1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','Fireplaces','GarageYrBlt',\n",
    "# 'GarageCars','GarageArea','ExterQual','BsmtQual','HeatingQC','KitchenQual','GarageFinish']]\n",
    "\n",
    "# test_my_final_X = test_f[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF',\n",
    "# '1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','Fireplaces','GarageYrBlt',\n",
    "# 'GarageCars','GarageArea','ExterQual','BsmtQual','HeatingQC','KitchenQual','GarageFinish']]\n",
    "\n",
    "# my_final_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.scatter(my_final_X['OverallQual'], Y, c='lightgray')\n",
    "# # plt.scatter(X_val['TV'], y_val, c='black')\n",
    "# # plt.plot(X_plot, y_single_plot, c='lightblue', linewidth=2, label='single linear')\n",
    "# # plt.plot(X_plot, y_poly_plot, c='blue', linewidth=2, label='polynomial')\n",
    "\n",
    "# plt.xlabel(\"OverallQual\")\n",
    "# plt.ylabel(\"SalePrice\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I concatenated the Extracted features with SalePrice and plotted a heatmap of their correlation matrix.  \n",
    "* I did that in order to remove any redundency between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dataset = pd.concat([\n",
    "#     my_final_X,\n",
    "#     pd.DataFrame(\n",
    "#         Y,\n",
    "#         index=Y.index,\n",
    "#         columns=['SalePrice']\n",
    "#     )\n",
    "# ],axis=1)\n",
    "\n",
    "# correlation = final_dataset.corr()\n",
    "# sns.set(rc = {'figure.figsize':(16,10)})\n",
    "# mask = np.triu(np.ones_like(correlation))\n",
    "# hmap = sns.heatmap(correlation, annot=True, mask=mask, cmap=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GarageArea and GarageCars feature are strongly positively correlated so I dropped GarageArea feature to avoid redundency and bias.  \n",
    "- Same thing, 1stFlrSF and TotalBsmtSF features strongly positively correlated so I dropped TotalBsmtSF feature.  \n",
    "- again same thing for TotRmsAbvGrd and GrLivArea, so I dropped TotRmsAbvGrd feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dataset = final_dataset.drop(['GarageArea','TotalBsmtSF', 'TotRmsAbvGrd'], axis=1)\n",
    "# test_my_final_X = test_my_final_X.drop(['GarageArea','TotalBsmtSF', 'TotRmsAbvGrd'], axis=1)\n",
    "# # test_my_final_X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I Scaled our X features in the training and testing sets using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# Y = final_dataset['SalePrice']\n",
    "# final_dataset_X = final_dataset.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# for i in final_dataset_X.columns:\n",
    "#     final_dataset_X[i] = scaler.fit_transform(final_dataset_X[[i]])\n",
    "\n",
    "# for i in test_my_final_X.columns:\n",
    "#     test_my_final_X[i] = scaler.fit_transform(test_my_final_X[[i]])\n",
    "\n",
    "# print(final_dataset_X.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Step: Split Data, Train Model and Evaluate it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I splitted the training set to (train & validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "# def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "#     rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "#     return round(rmsle, precision)\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(final_dataset_X, Y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined a Lasso regression model and trained it and use it to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "# Lasso = Lasso(alpha=2)\n",
    "\n",
    "\n",
    "# Lasso.fit(X_train, y_train)\n",
    "# y_pred = Lasso.predict(X_test)\n",
    "\n",
    "# compute_rmsle(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I used Random Forest regression model to test on it as well and compare wit hthe previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# mod = RandomForestRegressor()\n",
    "# mod.fit(X_train,y_train)\n",
    "# y_pred = mod.predict(X_test)\n",
    "# compute_rmsle(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I thought of plotting SalePrice & OverallQual (because it is the most correlated feature with SalePrice), and I noticed a curve like parabola  \n",
    "so I thought of fitting a polinomial regression model (because it is more flexible than linear single regression).  \n",
    "but it didn't give good results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "# x_poly_train = poly.fit_transform(X_train)\n",
    "# x_poly_test = poly.fit_transform(X_test)\n",
    "# model = LinearRegression()\n",
    "# model.fit(x_poly_train,y_train)\n",
    "# y_poly_pred = model.predict(x_poly_test)\n",
    "\n",
    "\n",
    "# x_poly_test_kaggle = poly.fit_transform(test_my_final_X)\n",
    "\n",
    "# compute_rmsle(y_test,y_poly_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Step: Submission File Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This cell just to prepare a submission file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_y_pred = model.predict(x_poly_test_kaggle)\n",
    "# Output = pd.DataFrame()\n",
    "# Output['Id'] = ids['Id']\n",
    "# Output['SalePrice'] = pd.DataFrame(test_y_pred, columns=['SalePrice'])\n",
    "# Output.to_csv('../submission_1.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96c5e9a996b9fb50791ed320c0dcd8c8bacd855edbfc9839eabc094339f470ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
